{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from dataset import MSCOCO\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location\n",
    "MAIN_FOLDER = \"/media/ubuntu/0832e13b-3a8e-4ba1-9bd4-8e0b767de9e7/home/robin/Téléchargements\"\n",
    "DATASET = \"val\"\n",
    "IMAGES_FOLDER = os.path.join(MAIN_FOLDER, \"{}2017_resized\".format(DATASET))\n",
    "ANNOTATION_FILE = os.path.join(MAIN_FOLDER, \"annotations_trainval2017/annotations/person_keypoints_{}2017.json\".format(DATASET))\n",
    "MODEL_PATH = \"/home/ubuntu/Downloads/model_9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "valset = MSCOCO(IMAGES_FOLDER, ANNOTATION_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from a checkpoint\n",
    "ckpt = torch.load(MODEL_PATH)\n",
    "model = Model()\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-768efe91f293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Figure with the image, the ground truth and the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image, ground truth and prediction for image #{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    # Figure with the image, the ground truth and the prediction\n",
    "    plt.figure()\n",
    "    plt.title(\"Image, ground truth and prediction for image #{}\".format(i))\n",
    "    \n",
    "    # Get an image\n",
    "    img, ground_truth = valset[i]\n",
    "\n",
    "    # Transform into a pytorch model input\n",
    "    img = Variable(img.unsqueeze(0))\n",
    "\n",
    "    # Display the input of the model\n",
    "    img_numpy = img.data.numpy().squeeze(0).transpose(2,1,0)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_numpy)\n",
    "    \n",
    "    # Get the prediction\n",
    "    heatmap = model(img)\n",
    "\n",
    "    # Display the prediction\n",
    "    heatmap_numpy = heatmap.data.numpy().squeeze(0).sum(0)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap_numpy)\n",
    "    \n",
    "    # Display the ground truth\n",
    "    ground_truth_numpy = keypoints.numpy().sum(0)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(ground_truth_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at each heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 100\n",
    "\n",
    "# Get an image\n",
    "img, ground_truth = valset[i]\n",
    "\n",
    "# Transform into a pytorch model input\n",
    "img = Variable(img.unsqueeze(0))\n",
    "\n",
    "# Display the input of the model\n",
    "img_numpy = img.data.numpy().squeeze(0).transpose(2,1,0)\n",
    "plt.figure()\n",
    "plt.imshow(img_numpy)\n",
    "\n",
    "# Get the output\n",
    "heatmap = model(img)\n",
    "\n",
    "# Display the heatmap\n",
    "heatmaps_numpy = heatmap.data.numpy()\n",
    "\n",
    "for k, heatmap_numpy in enumerate(heatmaps_numpy):\n",
    "    plt.figure()\n",
    "    plt.title(\"Prediction and ground truth #{} for image #{}\".format(k, i))\n",
    "    plt.imshow(heatmap_numpy)\n",
    "    plt.imshow(ground_truth.numpy()[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
